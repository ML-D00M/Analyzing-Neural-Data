{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data shape = ((34872, 16, 45)) after preprocessing\n",
    "\n",
    "#data shape change to 44\n",
    "\n",
    "with open('all_epochs.npy', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "    \n",
    "with open('all_labels.npy', 'rb') as f:\n",
    "    y = np.load(f)\n",
    "\n",
    "X.shape, y.shape\n",
    "\n",
    "#  train_EEG   test_EEG  split here\n",
    "#   train_labels test_labels  split here\n",
    "\n",
    "X = X[:,:,:,None]\n",
    "\n",
    "X.shape\n",
    "\n",
    "X = X[:,:,:-1,:]\n",
    "X.shape\n",
    "\n",
    "BUFFER_SIZE = 14424\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(4*11*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((4, 11, 256)))\n",
    "    assert model.output_shape == (None, 4, 11, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 4, 11, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 8, 22, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 16, 44, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2688641af70>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[16, 44, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.0004584]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-46-ae02327b3832>:10 train_step  *\n        real_output = discriminator(images, training=True)\n    C:\\Users\\schit\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\schit\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:191 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_9 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [16, 44, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-87f7f8678458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-66-802af7bf198a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m       \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Produce images for the GIF as we go\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-46-ae02327b3832>:10 train_step  *\n        real_output = discriminator(images, training=True)\n    C:\\Users\\schit\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\schit\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:191 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_9 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [16, 44, 1]\n"
     ]
    }
   ],
   "source": [
    "train(X, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_at_epoch_0050.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-7d0477526f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-8856f1fb1abc>\u001b[0m in \u001b[0;36mdisplay_image\u001b[1;34m(epoch_no)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image_at_epoch_{:04d}.png'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2877\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image_at_epoch_0050.png'"
     ]
    }
   ],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
